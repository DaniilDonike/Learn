[[Web mining]]

Вы отправили get-запрос и добыли код страницы. Выглядит круто, однако достать из этой строки чистые данные вручную сложно.

Чтобы решить проблему, обратимся к возможностям библиотеки **BeautifulSoup** (от англ. _beautiful soup,_ «красивый суп»). Имя библиотеки выбрано в противовес **tag soup** (англ. «суп из тегов»), как уничижительно называют неструктурированный, небрежно написанный код веб-страницы.

Методы библиотеки _BeautifulSoup_ превращают HTML-файл в древовидную структуру. После этого нужный контент можно отыскать по тегам и атрибутам.

Импортируем библиотеку и создадим объект _BeautifulSoup_:
```python
from bs4 import BeautifulSoup

soup = BeautifulSoup(req.text, 'lxml') 
```

Первый аргумент — это данные, из которых будет собираться древовидная структура. Второй аргумент — синтаксический анализатор, или парсер. Он отвечает за то, как именно из кода веб-страницы получается «дерево». Парсеров много, они создают разные структуры из одного и того же HTML-документа. За высокую скорость работы мы выбрали анализатор **lxml**. Есть и другие, например, _html.parser_, _xml_ или _html5lib_.

### Поиск по дереву

Мы превратили код в дерево. Время извлекать данные.

Первый метод поиска называется **find()** (англ. «найти»). В HTML-документе он находит первый элемент, имя которого ему передали в качестве аргумента, и возвращает его весь, с тегами и контентом. Найдём, к примеру, первый заголовок второго уровня:

Скопировать кодPYTHON

```python
heading_2=soup.find('h2')
print(heading_2) 
```

Скопировать кодPYTHON

```python
<h2>Крупнейшие морские катастрофы XX века</h2> 
```

Чтобы посмотреть контент без тега, вызывают метод **text**. Результат возвращается в виде строки:

```python
print(heading_2.text) 
```

```
Крупнейшие морские катастрофы XX века 
```

Существует и другой метод поиска — **find_all** (англ. «найти всё»). В отличие от предыдущего метода, _find_all()_ находит _все_ вхождения определённого элемента в HTML-документе и возвращает список:

```python
paragraph=soup.find_all('p')
print(paragraph) 
```

```
[<p>Благодаря массовой культуре морские катастрофы чаще всего ассоциируются с «Титаником». Однако в начале XX века столкновение парохода «Титаник» с айсбергом было не единственным кораблекрушением.</p>, <p>Теперь посмотрим на тех, кто был рядом с «Титаником»:</p>] 
```

Методом _text_ вычленим только контент из параграфов:

```python
for paragraph in soup.find_all('p'):
    print(paragraph.text) 
```

```
Благодаря массовой культуре морские катастрофы чаще всего ассоциируются с «Титаником». Однако в начале XX века
столкновение парохода «Титаник» с айсбергом было не единственным кораблекрушением.
Теперь посмотрим на тех, кто был рядом с «Титаником»: 
```

У методов _find()_ и _find_all()_ есть дополнительный фильтр поиска элементов страницы — параметр **attrs** (от англ. _attributes_, **«атрибуты»).

Это он охотится на идентификаторы и классы. Их имена уточняют в панели разработчика.

Параметру _attrs_ передают словарь с именами и значениями атрибутов. Вот разыскивается элемент с идентификатором `'ten_years_first'`:

```python
print(soup.find('table',attrs={'id': 'ten_years_first'})) 
```

```html
<table border="1" cellpadding="5" id="ten_years_first" width="100%">
<tr>
<th>Название корабля</th>
<th>Дата катастрофы</th>
<th>Место катастрофы</th>
<th>Причина катастрофы</th>
</tr>
<tr>
<td>«Генерал Слокам»</td>
<td>15 июня 1904 года</td>
<td>Ист-Ривер</td>
<td>Человеческий фактор</td>
</tr>
<tr>
<td>«Каморта»</td>
<td>6 мая 1902 года</td>
<td>Бенгальский залив</td>
<td>Природная стихия</td>
</tr>
<tr>
<td>«Норье»</td>
<td>28 июня 1904 года</td>
<td>Атлантический океан</td>
<td>Человеческий фактор</td>
</tr>
</table> 
```

Усложним задачу. Достанем таблицу с кораблекрушениями первого десятилетия XX века и превратим её в датафрейм:


```python
table = soup.find('table',attrs={'id': 'ten_years_first'})
# применим метод find к тегу table
# укажем атрибут первой таблицы: ten_years_first 
print(table) 
```

```html
<table border="1" cellpadding="5" id="ten_years_first" width="100%">
<tr>
<th>Название корабля</th>
<th>Дата катастрофы</th>
<th>Место катастрофы</th>
<th>Причина катастрофы</th>
</tr>
<tr>
<td>«Генерал Слокам»</td>
<td>15 июня 1904 года</td>
<td>Ист-Ривер</td>
<td>Человеческий фактор</td>
</tr>
<tr>
<td>«Каморта»</td>
<td>6 мая 1902 года</td>
<td>Бенгальский залив</td>
<td>Природная стихия</td>
</tr>
<tr>
<td>«Норье»</td>
<td>28 июня 1904 года</td>
<td>Атлантический океан</td>
<td>Человеческий фактор</td>
</tr>
</table> 
```

Напомним, что открывающий тег `<table>` указывает начало таблицы, а закрывающий `</table>` — её конец. Внутри теги строк — `<tr>`; ячеек — `<td>` и заголовков столбцов — `<th>`.

Создадим пустой список _heading_table_, где сохраним названия столбцов. В цикле методом _find_all()_ найдём все элементы `th`. Методом _text_ добудем их контент и добавим его в список _heading_table_:

Скопировать кодPYTHON

```python
heading_table = [] # Список, в котором будут храниться названия столбцов
for row in table.find_all('th'): # Названия столбцов прячутся в элементах th, 
# поэтому будем искать все элементы th внутри table и пробегать по ним в цикле
        heading_table.append(row.text) # Добавляем контент из тега th в список heading_table методом append()
print(heading_table) 
```

```
['Название корабля', 'Дата катастрофы', 'Место катастрофы', 'Причина катастрофы'] 
```

Создадим пустой список _content_, сохраним там данные таблицы. В цикле обратимся к каждой строке по имени элемента `tr`.

Отдельно отметим, что самая первая строка таблицы с заголовками в тегах `<th> </th>`, нас не интересует. Потому перед тем, как в цикле добавлять значения в пустой список, укажем, что это не касается строки с заголовками: `if not row.find_all('th')`.

Применим метод _find_all()_ к элементам _td_. Методом _text_ очистим полученные ячейки от тегов и сложим в список _content_.

```python
content=[] # Список, в котором будут храниться данные из таблицы
for row in table.find_all('tr'): 
# Каждая строка обрамляется тегом tr, необходимо пробежаться в цикле по всем строкам
    if not row.find_all('th'): 
# Эта проверка необходима, чтобы пропустить первую строку таблицы с заголовками
            content.append([element.text for element in row.find_all('td')])
            # В каждой строке контент ячейки обрамляется тегами <td> </td>
            # Необходимо пробежаться в цикле по всем элементам td, вычленить контент из ячеек и добавить его в список 
            # Затем добавить каждый из списков в список content 
print(content) 
```

```
[['«Генерал Слокам»', '15 июня 1904 года', 'Ист-Ривер', 'Человеческий фактор'], ['«Каморта»', '6 мая 1902 года', 'Бенгальский залив', 'Природная стихия'], ['«Норье»', '28 июня 1904 года', 'Атлантический океан', 'Человеческий фактор']] 
```

В результате мы получили 2 списка. В списке _heading_table_ сохранили названия столбцов. В _content —_ наполнение таблицы в виде двумерного массива.

```python
import pandas as pd
shipwrecks = pd.DataFrame(content, columns=heading_table) 
# в качестве данных передаем двумерный список content, а в качестве заголовков - heading_table
print(shipwrecks.head()) 
```

```
   Название корабля    Дата катастрофы     Место катастрофы  \
0  «Генерал Слокам»  15 июня 1904 года            Ист-Ривер   
1         «Каморта»    6 мая 1902 года    Бенгальский залив   
2           «Норье»  28 июня 1904 года  Атлантический океан   

    Причина катастрофы  
0  Человеческий фактор  
1     Природная стихия  
2  Человеческий фактор   
```

Мы преобразовали таблицу с сайта в хорошо знакомый вам датафрейм! Теперь с ним можно делать всё, что вы уже умеете с таблицами.